{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat  파일 길이 :  602\n",
      "cat  :  /Users/jiwon/Desktop/female/cat/823.jpg\n",
      "dog  파일 길이 :  579\n",
      "dog  :  /Users/jiwon/Desktop/female/dog/63.jpg\n",
      "rodent  파일 길이 :  339\n",
      "rodent  :  /Users/jiwon/Desktop/female/rodent/rodent130.jpg\n",
      "ok 1520\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os, glob, numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "caltech_dir = \"/Users/jiwon/Desktop/female\"\n",
    "categories = [\"cat\",\"dog\",\"rodent\"]\n",
    "nb_classes = len(categories)\n",
    "\n",
    "image_w = 64\n",
    "image_h = 64\n",
    "\n",
    "pixels = image_h * image_w * 3\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for idx, cat in enumerate(categories):\n",
    "    \n",
    "    #one-hot 돌리기.\n",
    "    label = [0 for i in range(nb_classes)]\n",
    "    label[idx] = 1\n",
    "\n",
    "    image_dir = caltech_dir + \"/\" + cat\n",
    "    files = glob.glob(image_dir+\"/*.jpg\")\n",
    "    print(cat, \" 파일 길이 : \", len(files))\n",
    "    for i, f in enumerate(files):\n",
    "        img = Image.open(f)\n",
    "        img = img.convert(\"RGB\")\n",
    "        img = img.resize((image_w, image_h))\n",
    "        data = np.asarray(img)\n",
    "\n",
    "        X.append(data)\n",
    "        y.append(label)\n",
    "\n",
    "        if i % 700 == 0:\n",
    "            print(cat, \" : \", f)\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "#1 0 0 0 이면 airplanes\n",
    "#0 1 0 0 이면 buddha 이런식\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "xy = (X_train, X_test, y_train, y_test)\n",
    "np.save(\"/Users/jiwon/Desktop/numpy_data/multi_image_data.npy\", xy)\n",
    "\n",
    "print(\"ok\", len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/jiwon/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/jiwon/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/jiwon/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/jiwon/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/jiwon/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/jiwon/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/jiwon/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/jiwon/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/jiwon/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/jiwon/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/jiwon/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/jiwon/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1140, 64, 64, 3)\n",
      "1140\n"
     ]
    }
   ],
   "source": [
    "import os, glob, numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.backend.tensorflow_backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n",
    "\n",
    "X_train, X_test, y_train, y_test = np.load('/Users/jiwon/Desktop/numpy_data/multi_image_data.npy',allow_pickle=True)\n",
    "print(X_train.shape)\n",
    "print(X_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\"cat\",\"dog\",\"rodent\"]\n",
    "nb_classes = len(categories)\n",
    "\n",
    "#일반화\n",
    "X_train = X_train.astype(float) / 255\n",
    "X_test = X_test.astype(float) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/jiwon/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with K.tf_ops.device('/device:GPU:0'):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3,3), padding=\"same\", input_shape=X_train.shape[1:], activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv2D(64, (3,3), padding=\"same\", activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(nb_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model_dir = './model'\n",
    "    \n",
    "    if not os.path.exists(model_dir):\n",
    "        os.mkdir(model_dir)\n",
    "    \n",
    "    model_path = model_dir + '/multi_img_classification.model'\n",
    "    checkpoint = ModelCheckpoint(filepath=model_path , monitor='val_loss', verbose=1, save_best_only=True)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 64, 64, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               4194560   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 4,214,723\n",
      "Trainable params: 4,214,723\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/jiwon/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 912 samples, validate on 228 samples\n",
      "Epoch 1/50\n",
      "912/912 [==============================] - 5s 5ms/step - loss: 1.1831 - accuracy: 0.4035 - val_loss: 1.0746 - val_accuracy: 0.4123\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.07464, saving model to ./model/multi_img_classification.model\n",
      "Epoch 2/50\n",
      "912/912 [==============================] - 4s 4ms/step - loss: 1.0639 - accuracy: 0.4386 - val_loss: 1.0668 - val_accuracy: 0.4167\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.07464 to 1.06684, saving model to ./model/multi_img_classification.model\n",
      "Epoch 3/50\n",
      "912/912 [==============================] - 4s 4ms/step - loss: 1.0441 - accuracy: 0.4781 - val_loss: 1.0348 - val_accuracy: 0.4298\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.06684 to 1.03481, saving model to ./model/multi_img_classification.model\n",
      "Epoch 4/50\n",
      "912/912 [==============================] - 4s 4ms/step - loss: 1.0126 - accuracy: 0.4868 - val_loss: 1.0337 - val_accuracy: 0.4474\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.03481 to 1.03366, saving model to ./model/multi_img_classification.model\n",
      "Epoch 5/50\n",
      "912/912 [==============================] - 4s 4ms/step - loss: 0.9906 - accuracy: 0.5110 - val_loss: 1.0063 - val_accuracy: 0.4430\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.03366 to 1.00626, saving model to ./model/multi_img_classification.model\n",
      "Epoch 6/50\n",
      "912/912 [==============================] - 4s 5ms/step - loss: 0.9482 - accuracy: 0.5493 - val_loss: 0.9947 - val_accuracy: 0.4912\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.00626 to 0.99471, saving model to ./model/multi_img_classification.model\n",
      "Epoch 7/50\n",
      "912/912 [==============================] - 4s 5ms/step - loss: 0.9308 - accuracy: 0.5658 - val_loss: 1.0058 - val_accuracy: 0.4298\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.99471\n",
      "Epoch 8/50\n",
      "912/912 [==============================] - 4s 5ms/step - loss: 0.8918 - accuracy: 0.5844 - val_loss: 0.9852 - val_accuracy: 0.5219\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.99471 to 0.98520, saving model to ./model/multi_img_classification.model\n",
      "Epoch 9/50\n",
      "912/912 [==============================] - 4s 5ms/step - loss: 0.8502 - accuracy: 0.6151 - val_loss: 1.0019 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.98520\n",
      "Epoch 10/50\n",
      "912/912 [==============================] - 4s 5ms/step - loss: 0.7931 - accuracy: 0.6491 - val_loss: 0.9929 - val_accuracy: 0.4825\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.98520\n",
      "Epoch 11/50\n",
      "912/912 [==============================] - 4s 4ms/step - loss: 0.7620 - accuracy: 0.6711 - val_loss: 1.0473 - val_accuracy: 0.4649\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.98520\n",
      "Epoch 12/50\n",
      "912/912 [==============================] - 4s 4ms/step - loss: 0.7342 - accuracy: 0.6787 - val_loss: 0.9996 - val_accuracy: 0.5307\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.98520\n",
      "Epoch 13/50\n",
      "912/912 [==============================] - 4s 5ms/step - loss: 0.6531 - accuracy: 0.7325 - val_loss: 1.0139 - val_accuracy: 0.5219\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.98520\n",
      "Epoch 14/50\n",
      "912/912 [==============================] - 4s 4ms/step - loss: 0.6008 - accuracy: 0.7544 - val_loss: 1.0494 - val_accuracy: 0.5175\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.98520\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, validation_split=0.2, batch_size=32, epochs=50, callbacks=[checkpoint, early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "380/380 [==============================] - 0s 858us/step\n",
      "정확도 : 0.4579\n"
     ]
    }
   ],
   "source": [
    "print(\"정확도 : %.4f\" % (model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_vloss = history.history['val_loss']\n",
    "y_loss = history.history['loss']\n",
    "\n",
    "x_len = np.arange(len(y_loss))\n",
    "\n",
    "plt.plot(x_len, y_vloss, marker='.', c='red', label='val_set_loss')\n",
    "plt.plot(x_len, y_loss, marker='.', c='blue', label='train_set_oss')\n",
    "plt.legend()\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.000 1.000 0.000]\n",
      "1\n",
      "해당 /Users/jiwon/Desktop/test/정유미.jpg이미지는 dog으로 추정됩니다.\n",
      "[0.000 0.000 1.000]\n",
      "2\n",
      "해당 /Users/jiwon/Desktop/test/나연.jpeg이미지는 rodent으로 추정됩니다.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os, glob, numpy as np\n",
    "from keras.models import load_model\n",
    "caltech_dir = \"/Users/jiwon/Desktop/test\"\n",
    "# caltech_dir = \"./multi_img_data/imgs_others_test\"\n",
    "image_w = 64\n",
    "image_h = 64\n",
    "\n",
    "pixels = image_h * image_w * 3\n",
    "\n",
    "X = []\n",
    "filenames = []\n",
    "files = glob.glob(caltech_dir+\"/*.*\")\n",
    "for i, f in enumerate(files):\n",
    "    img = Image.open(f)\n",
    "    img = img.convert(\"RGB\")\n",
    "    img = img.resize((image_w, image_h))\n",
    "    data = np.asarray(img)\n",
    "    filenames.append(f)\n",
    "    X.append(data)\n",
    "    \n",
    "X = np.array(X)\n",
    "\n",
    "\n",
    "# np.resize(img, (-1, <image shape>)\n",
    "# model = load_model('./model/multi_img_classification.model')\n",
    "#model = load_model('/Users/jiwon/model/multi_img_classification.model')\n",
    "model = load_model('./model/multi_img_classification.model')\n",
    "# X = X.reshape(X_train.shape[0], 720, 1280, 1)\n",
    "prediction = model.predict(X)\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "cnt = 0\n",
    "\n",
    "#이 비교는 그냥 파일들이 있으면 해당 파일과 비교. 카테고리와 함께 비교해서 진행하는 것은 _4 파일.\n",
    "for i in prediction:\n",
    "    pre_ans = i.argmax()  # 예측 레이블\n",
    "    print(i)\n",
    "    print(pre_ans)\n",
    "    pre_ans_str = ''\n",
    "    if pre_ans == 0: pre_ans_str = \"cat\"\n",
    "    elif pre_ans == 1: pre_ans_str = \"dog\"\n",
    "    else : pre_ans_str = \"rodent\"\n",
    "    if i[0] >= 0.8 : print(\"해당 \"+filenames[cnt].split(\"\\\\\")[0]+\"이미지는 \"+pre_ans_str+\"로 추정됩니다.\")\n",
    "    if i[1] >= 0.8: print(\"해당 \"+filenames[cnt].split(\"\\\\\")[0]+\"이미지는 \"+pre_ans_str+\"으로 추정됩니다.\")\n",
    "    if i[2] >= 0.8: print(\"해당 \"+filenames[cnt].split(\"\\\\\")[0]+\"이미지는 \"+pre_ans_str+\"으로 추정됩니다.\")\n",
    "    cnt += 1\n",
    "    # print(i.argmax()) #얘가 레이블 [1. 0. 0.] 이런식으로 되어 있는 것을 숫자로 바꿔주는 것.\n",
    "    # 즉 얘랑, 나중에 카테고리 데이터 불러와서 카테고리랑 비교를 해서 같으면 맞는거고, 아니면 틀린거로 취급하면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/jiwon/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From <ipython-input-10-2d9a5ac35181>:17: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /Users/jiwon/opt/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /Users/jiwon/opt/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting mnist/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/jiwon/opt/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting mnist/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/jiwon/opt/anaconda3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /Users/jiwon/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /Users/jiwon/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /Users/jiwon/opt/anaconda3/lib/python3.7/site-packages/tensorflow/lite/python/util.py:238: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
      "WARNING:tensorflow:From /Users/jiwon/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/graph_util_impl.py:270: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "INFO:tensorflow:Froze 2 variables.\n",
      "INFO:tensorflow:Converted 2 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import os\n",
    "import numpy as np\n",
    "import PIL\n",
    "\n",
    "np.set_printoptions(linewidth=1000)\n",
    "\n",
    "def save_model(h5_path, model_path):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(10, activation='softmax', input_shape=[784]))\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001),\n",
    "                  loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "                  metrics=['acc'])\n",
    "\n",
    "    mnist = input_data.read_data_sets('mnist')\n",
    "    model.fit(mnist.train.images, mnist.train.labels,\n",
    "              validation_data=[mnist.validation.images, mnist.validation.labels],\n",
    "              epochs=15, batch_size=128, verbose=0)\n",
    "\n",
    "    model.save(h5_path)\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model_file(h5_path)\n",
    "    flat_data = converter.convert()\n",
    "\n",
    "    with open(model_path, 'wb') as f:\n",
    "        f.write(flat_data)\n",
    "\n",
    "save_model('./mnist.h5', './mnist.tflite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
